{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Makam Recognition\n",
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from mutagen.mp3 import MP3\n",
    "import librosa\n",
    "from scipy.interpolate import interp2d \n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from math import floor\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading using provided folds and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with: ./soundfiles/1e716ab1-3501-43c8-807b-4fc6180a91f1.mp3\n",
      "Problem with: ./soundfiles/5a44e069-3b0e-4a28-b515-b7b257b6373a.mp3\n",
      "Problem with: ./soundfiles/653f8154-b374-4713-99ee-f649f9582b99.mp3\n",
      "Problem with: ./soundfiles/75c034d1-11e0-4851-93d8-a07ba41fae81.mp3\n",
      "./soundfiles/b351600d-1ed2-4c69-9662-1677d4cb0fa7.mp3\n",
      "./soundfiles/bca7c2e4-3263-4022-9de2-42fc70848c85.mp3\n",
      "./soundfiles/71f8bdfc-6181-43b0-a993-29badae80ddd.mp3\n",
      "./soundfiles/035d177c-72dd-49c5-b0ca-94c808bfb4c0.mp3\n",
      "./soundfiles/3c0f63ff-95a3-45eb-9be8-6ef811760ab3.mp3\n",
      "./soundfiles/f4a426fb-cf87-4fa4-9ee7-a230f4e7307c.mp3\n",
      "./soundfiles/dce94bb4-447a-439c-a1d6-20e8551aa85f.mp3\n",
      "./soundfiles/cfafca28-1bf7-431b-8440-a61c1bdf8e58.mp3\n",
      "./soundfiles/d69470ef-dee5-4a11-9098-9135be5288d7.mp3\n",
      "./soundfiles/d726cd51-fda8-467e-aa08-3d75f2fffc07.mp3\n",
      "./soundfiles/e9d8706e-913d-4a64-bd9d-7324ca4ddd41.mp3\n",
      "./soundfiles/4bd265f0-06a5-46d8-b727-c2e799b1cdf8.mp3\n",
      "./soundfiles/feda89e3-a50d-4ff8-87d4-c1e531cc1233.mp3\n",
      "./soundfiles/70a9b17d-0ac8-4296-9321-ee396d2de4c9.mp3\n",
      "./soundfiles/f716d17e-c086-4011-b95b-4c75ec998e18.mp3\n",
      "./soundfiles/37183c6f-6fd6-4d61-9d65-1f7b34ef8fa8.mp3\n",
      "./soundfiles/2f74c34a-b5a4-496c-b192-8a5f71536a37.mp3\n",
      "./soundfiles/af7fd1eb-f077-4245-836b-83d86732924b.mp3\n",
      "./soundfiles/e29de35e-8ce5-41ec-9a19-6fbbfd39a9b5.mp3\n",
      "./soundfiles/bd293a02-37a5-4c6e-a04d-c1f411211392.mp3\n",
      "./soundfiles/8045c841-b1f9-4732-b2b4-dbf618bb7c94.mp3\n",
      "./soundfiles/c93d974b-2b71-4336-a0f2-7a7924c4ec98.mp3\n",
      "./soundfiles/63b6d5a6-f086-4c7e-9cba-45a4b9bca2b5.mp3\n",
      "./soundfiles/4859c4b7-4b02-4429-9413-c316ff488465.mp3\n",
      "./soundfiles/ca02f8b8-f3df-4791-9e07-e9e0960ab20e.mp3\n",
      "./soundfiles/e2e5febb-1ad2-4478-adf6-47e4ee534b16.mp3\n",
      "./soundfiles/9337924d-ff88-4ed2-85d0-35fddb2e1eee.mp3\n",
      "./soundfiles/ee0a4b14-d968-4467-b418-3051b5818152.mp3\n",
      "./soundfiles/3799145c-529c-41d2-998a-948a9292f4d8.mp3\n",
      "./soundfiles/5b9713dd-de22-46e4-8037-e632f08caa80.mp3\n",
      "./soundfiles/f6e57a29-4e93-4a70-8dc3-86fae1cb9f3b.mp3\n",
      "./soundfiles/bdc86dc2-a23f-4a1a-a311-a1a14177de1a.mp3\n",
      "./soundfiles/9159ad88-77d7-4e40-9861-3f15bc4bd6d4.mp3\n",
      "./soundfiles/4371d5e2-42d0-4ec8-b150-e0db0539c750.mp3\n",
      "./soundfiles/833f9c6f-ab05-4b42-a3ca-68e41b606667.mp3\n",
      "./soundfiles/f95996b8-452d-4e7f-baa6-ded041a4ec35.mp3\n",
      "./soundfiles/d35e07f4-fbf5-4efb-8a36-721565fa8044.mp3\n",
      "./soundfiles/d6e84d9f-bf51-473e-a54d-26b9b2f52f2e.mp3\n",
      "./soundfiles/0f0e4bc3-67f9-4727-818b-983320e897cb.mp3\n",
      "./soundfiles/a80b0276-f769-433c-8944-d316848409c5.mp3\n",
      "./soundfiles/ff1c2be9-fbba-4fb2-a457-037a59c8ce24.mp3\n",
      "./soundfiles/eb6c2c8d-b6c9-401a-af6f-960c40906325.mp3\n",
      "./soundfiles/7855739e-96cf-4210-9bb7-c7f59e4937a6.mp3\n",
      "./soundfiles/5c3218e4-79d4-424e-a169-3d4cd156dc1a.mp3\n",
      "./soundfiles/de29cf5a-0a91-4dde-aa18-139688f2b109.mp3\n",
      "./soundfiles/7a31af52-be40-4f09-b9bd-67c17ed73740.mp3\n",
      "./soundfiles/a95ba115-76e2-4cf6-bccb-30a6c790fcef.mp3\n",
      "./soundfiles/e411fd99-d149-4e4a-b3be-34fd5775c51d.mp3\n",
      "./soundfiles/d3368e9e-7d77-4f10-8078-b92c580e4142.mp3\n",
      "./soundfiles/67866b98-67ec-4d23-89d9-02bc1eeca464.mp3\n",
      "./soundfiles/f6dd16a4-84e9-4cdf-8075-ce7dceedc483.mp3\n",
      "./soundfiles/fb95a551-f535-4bfb-a7df-420e909949b1.mp3\n",
      "./soundfiles/380f7d83-8602-47e2-a002-e8eae420d256.mp3\n",
      "./soundfiles/6fca9e03-dbb5-467d-8a33-234360643b37.mp3\n",
      "./soundfiles/4275e885-15b4-44d8-8296-64b0226d1eb9.mp3\n",
      "./soundfiles/3585204e-4b75-486a-acad-547c88c62965.mp3\n",
      "./soundfiles/221e5475-a79d-4995-8968-d7dc52dc387b.mp3\n",
      "./soundfiles/6fe95c93-5927-455d-bef1-7d400158f09f.mp3\n",
      "./soundfiles/05893ab9-4fbe-4d70-8df0-9cb99cab297a.mp3\n",
      "./soundfiles/ba52af98-f2e7-4dd5-8bc2-342e84091990.mp3\n",
      "./soundfiles/a2e650dc-8822-4647-9f4c-c41c0f81b601.mp3\n",
      "./soundfiles/411a69c1-c016-45cd-bdbf-5bbe3dfa6d3c.mp3\n",
      "./soundfiles/fae0590a-0913-4637-8005-e85e0c439063.mp3\n",
      "./soundfiles/a88c72e7-0223-46d1-a970-9fb3acec7e32.mp3\n",
      "./soundfiles/6236a1e6-e29f-4cad-89db-b215940754d9.mp3\n",
      "./soundfiles/f98e829c-1a9b-4170-a7d7-34a1a2d857ee.mp3\n",
      "./soundfiles/5be58089-8726-4cbc-854d-f3d6a3e34a2b.mp3\n",
      "./soundfiles/86ea3034-2212-49d8-abe4-60b88c88a5ec.mp3\n",
      "./soundfiles/05631670-dac1-4336-a3ab-ae94eb04344b.mp3\n",
      "./soundfiles/06521d43-4953-411d-b017-8a3916ccf741.mp3\n",
      "./soundfiles/92e8f672-b859-4646-bd24-0515f25ca063.mp3\n",
      "./soundfiles/ed187560-ae33-455a-98a3-224f72b0e127.mp3\n",
      "./soundfiles/cf134df3-676e-4e09-92a2-bade5712060c.mp3\n",
      "./soundfiles/7693fcf6-4a57-4dc2-b505-4f3d87ca71d0.mp3\n",
      "./soundfiles/e72db0ad-2ed9-467b-88ae-1f91edcd2c59.mp3\n",
      "./soundfiles/20a1ddac-39a4-4bbb-81f5-bee504540f02.mp3\n",
      "./soundfiles/43383c69-f078-49bb-8f89-848d65156ee7.mp3\n",
      "./soundfiles/3a2da49a-bf3e-4d90-8033-a9b221cbb292.mp3\n",
      "./soundfiles/865640ea-c9a2-4957-aa38-51ba264e3a6f.mp3\n",
      "./soundfiles/5e5c9094-38af-4ad1-85d5-ccf3b4d3d0db.mp3\n",
      "./soundfiles/8b8d697b-cad9-446e-ad19-5e85a36aa253.mp3\n",
      "./soundfiles/3169d091-28e2-439f-96d5-54f54ae372b7.mp3\n",
      "./soundfiles/b9c3e50e-45ce-46bf-a289-5d15123be49f.mp3\n",
      "./soundfiles/09ebd228-ac3a-412c-ab47-3a138156eeeb.mp3\n",
      "./soundfiles/15434940-b1f0-4ca4-9c7f-8a09b09d9bc2.mp3\n",
      "./soundfiles/c3eb4ecc-2602-4804-be04-47740b8fa3bd.mp3\n",
      "./soundfiles/b2454a8d-96f8-4c9e-ba1b-9ec0ba2389d9.mp3\n",
      "./soundfiles/a4170fcb-1071-4055-b958-ead9744e0d3d.mp3\n",
      "./soundfiles/dc6c0e8a-8c9a-435d-a7ca-5e044a764fbc.mp3\n",
      "./soundfiles/02736cb8-0e87-4b51-82b7-68c1ecbd02eb.mp3\n",
      "./soundfiles/7af747c6-bef7-4a93-a41a-d834af57501c.mp3\n",
      "./soundfiles/1931cca6-5d64-4b54-b0ca-87ddc57b5008.mp3\n",
      "./soundfiles/02ad436a-7987-4881-bdd7-ac49e1a65584.mp3\n",
      "./soundfiles/61b3188f-ef54-447f-b62a-fb0c21dbae61.mp3\n",
      "./soundfiles/9566c9df-1a60-4a8f-bd02-c846e3cbee6b.mp3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e092aa73d302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;31m#load soundfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0;31m#compute the constant-Q transform from audio signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mcqt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcqt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_bins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins_per_octave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins_per_octave\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#up to C7 in 53TET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(y, orig_sr, target_sr, res_type, fix, scale, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample_poly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mgcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresampy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/resampy/core.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(x, sr_orig, sr_new, axis, filter, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mx_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0my_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0mresample_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_win\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterp_delta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#--------PARAMETERS--------#\n",
    "\n",
    "#Choose truncation option\n",
    "# 1 : 15 seconds starting from the start\n",
    "# 2 : 15 seconds around the middle\n",
    "# 3 : 15 seconds from the end\n",
    "trunc_option = 2\n",
    "\n",
    "#Choose bins and bins per octave\n",
    "n_bins = 371\n",
    "bins_per_octave = 53\n",
    "\n",
    "#--------------------------#\n",
    "\n",
    "#Ignore mp3 read warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "\n",
    "#Arrays containing all constant-Q transforms of the soundfiles per fold\n",
    "X_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Array containing all makam labels per fold\n",
    "y_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Import folds\n",
    "f = open(\"./dlfm_makam_recognition_data/folds.json\")\n",
    "folds = json.load(f)\n",
    "\n",
    "#Compute cqts and import labels\n",
    "for i in range(len(folds)): #in number of folds\n",
    "    \n",
    "    \n",
    "    #compute all training cqts and import train labels\n",
    "    for source in range(len(folds[i][1][\"training\"][\"sources\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"training\"][\"sources\"][source] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        audio = MP3(file_name)\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        X_train[i].append(cqt)\n",
    "        \n",
    "        #import makam training label\n",
    "        y_train[i].append(folds[i][1][\"training\"][\"modes\"][source])\n",
    "        \n",
    "        \n",
    "    #compute all testing cqts and import test labels\n",
    "    for ref in range(len(folds[i][1][\"testing\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"testing\"][ref][\"source\"] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        X_test[i].append(cqt)\n",
    "        \n",
    "        #import makam testing label\n",
    "        y_test[i].append(folds[i][1][\"testing\"][ref][\"mode\"])\n",
    "        \n",
    "    print(\"Fold\", i, \"loaded.\")\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target vector\n",
    "Y_train = to_categorical(y_train)\n",
    "Y_test = to_categorical(y_test)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(len(folds)):\n",
    "    #Network topology\n",
    "    model = Sequential()\n",
    "\n",
    "    #3 convolutional layers\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "for i in range(len(folds)):\n",
    "    history = model[i].fit(X_train[i], Y_train[i], validation_split=0.25, epochs=10, batch_size=30)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "y_pred = []\n",
    "for i in range(len(folds)):\n",
    "    score = model[i].evaluate(X_test[i], Y_test[i], verbose=1)\n",
    "    scores.append(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
