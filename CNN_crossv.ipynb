{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Makam Recognition\n",
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from mutagen.mp3 import MP3\n",
    "import librosa\n",
    "from scipy.interpolate import interp2d \n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from math import floor\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading using provided folds and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------PARAMETERS--------#\n",
    "\n",
    "#Choose truncation option\n",
    "# 1 : 15 seconds starting from the start\n",
    "# 2 : 15 seconds around the middle\n",
    "# 3 : 15 seconds from the end\n",
    "trunc_option = 2\n",
    "\n",
    "#Choose bins and bins per octave\n",
    "n_bins = 371\n",
    "bins_per_octave = 53\n",
    "\n",
    "#--------------------------#\n",
    "\n",
    "#Ignore mp3 read warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "\n",
    "makams = [\"Acemasiran\", \"Acemkurdi\", \"Bestenigar\", \"Beyati\", \"Hicaz\", \"Hicazkar\", \"Huseyni\", \"Huzzam\", \"Karcigar\", \"Kurdilihicazkar\", \"Mahur\", \"Muhayyer\", \"Neva\", \"Nihavent\", \"Rast\", \"Saba\", \"Segah\", \"Sultaniyegah\", \"Suzinak\", \"Ussak\"]\n",
    "\n",
    "#Arrays containing all constant-Q transforms of the soundfiles per fold\n",
    "X_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Array containing all makam labels per fold\n",
    "y_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Import folds\n",
    "f = open(\"./dlfm_makam_recognition_data/folds_updated.json\")\n",
    "folds = json.load(f)\n",
    "\n",
    "\n",
    "#Compute cqts and import labels\n",
    "for i in range(2): #in number of folds\n",
    "    \n",
    "    \n",
    "    #compute all training cqts and import train labels\n",
    "    for source in range(len(folds[i][1][\"training\"][\"sources\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"training\"][\"sources\"][source] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        audio = MP3(file_name)\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        #Normalization\n",
    "        cqt = (cqt - np.mean(cqt)) / (np.std(cqt) + 1e-8)\n",
    "        \n",
    "        X_train[i].append(cqt)\n",
    "        \n",
    "        #import makam training label\n",
    "        y_train[i].append(makams.index(folds[i][1][\"training\"][\"modes\"][source]))\n",
    "        \n",
    "        \n",
    "    #compute all testing cqts and import test labels\n",
    "    for ref in range(len(folds[i][1][\"testing\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"testing\"][ref][\"source\"] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        #Normalization\n",
    "        cqt = (cqt - np.mean(cqt)) / (np.std(cqt) + 1e-8)\n",
    "        \n",
    "        X_test[i].append(cqt)\n",
    "        \n",
    "        #import makam testing label\n",
    "        y_test[i].append(makams.index(folds[i][1][\"testing\"][ref][\"mode\"]))\n",
    "        \n",
    "    print(\"Fold\", i, \"loaded.\")\n",
    "\n",
    "print(\"X_train shape:\", len(X_train), len(X_train[0]), X_train[0][0].shape)\n",
    "print(\"X_test shape:\", len(X_test), len(X_test[0]), X_test[0][0].shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"y_test shape:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-40cbb400bd43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mY_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2666\u001b[0m     \"\"\"\n\u001b[1;32m   2667\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2668\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "#one-hot encode target vector\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "for i in range(len(y_train)):\n",
    "    Y_train.append(to_categorical(np.asarray(y_train[i])))\n",
    "    Y_test.append(to_categorical(np.asarray(y_test[i])))\n",
    "Y_train = to_categorical(np.asarray(y_train))\n",
    "Y_test = to_categorical(np.asarray(y_test))\n",
    "#channel dimension\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = (np.asarray(X_train[i])).reshape(len(X_train[i]), X_train[i][0].shape[0], X_train[i][0].shape[1], 1)\n",
    "    X_test[i] = (np.asarray(X_test[i])).reshape(len(X_test[i]), X_test[i][0].shape[0], X_test[i][0].shape[1], 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"y_test shape:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(len(folds)):\n",
    "    #Network topology\n",
    "    model = Sequential()\n",
    "\n",
    "    #3 convolutional layers\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "for i in range(len(folds)):\n",
    "    history = model[i].fit(X_train[i], Y_train[i], validation_split=0.25, epochs=10, batch_size=30)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "y_pred = []\n",
    "for i in range(len(folds)):\n",
    "    score = model[i].evaluate(X_test[i], Y_test[i], verbose=1)\n",
    "    scores.append(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
