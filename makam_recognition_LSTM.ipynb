{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makam pitch sequence classification with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pitch files\n",
    "\n",
    "Before proceeding, the pitch files on the CompMusic Dunya makam corpus need to be converted in the quantized pitch series encoding constructed as described in the pseudocode below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for (all lines):\n",
    "--->delete value if 0\n",
    "--->quantize value to scale (e.g. 53ET) // pad start of pitch value with zeros appropriately so that the length of the pitch value is 5 e.g. 130 -> 00130\n",
    "    \n",
    "for (all lines):\n",
    "--->merge all neighboring values to one, and keep track of the number of consecutive occurrences k e.g. 1300\\n 1200\\n 1200\\n 1200\\n 760\\n 760\\n will become 1300,1\\n 1200,3\\n 760,2\\n\n",
    "    \n",
    "find kmin and kmax\t\n",
    "\n",
    "for (all lines):\n",
    "--->if k < (kmin + 0.25*(kmax-kmin)): replace with 1\n",
    "--->if (kmin + 0.25*(kmax-kmin)) < k < (kmin + 0.75*(kmax-kmin)): replace with 2\n",
    "--->If k > (kmin + 0.75*(kmax-kmin)): replace with 3\n",
    "\n",
    "//We now have a quantized pitch series encoding with a line format of pitch,significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading, octave folded encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File number: 1000\n",
      "Array length: 1000\n"
     ]
    }
   ],
   "source": [
    "#quantized octave-folded pitch file directory\n",
    "ofq_read_dir = \"./octfold_qdata/\" \n",
    "\n",
    "#Makam list for more efficient file searching during label retrieval\n",
    "makams = [\"Acemasiran\", \"Acemkurdi\", \"Bestenigar\", \"Beyati\", \"Hicaz\", \"Hicazkar\", \"Huseyni\", \"Huzzam\", \"Karcigar\", \"Kurdilihicazkar\", \"Mahur\", \"Muhayyer\", \"Neva\", \"Nihavent\", \"Rast\", \"Saba\", \"Segah\", \"Sultaniyegah\", \"Suzinak\", \"Ussak\"]\n",
    "\n",
    "all_qpitch = [] #array holding all quantized pitch series as strings\n",
    "y = [] #holds makam labels\n",
    "max_length = 0\n",
    "for root, dirs, files in os.walk(ofq_read_dir):\n",
    "    for name in files:\n",
    "        if '.pitch' in name:\n",
    "            #retrieve label from parent of original path\n",
    "            for makam in makams:\n",
    "                if (os.path.isfile(\"./otmm_makam_recognition_dataset/data/\" + makam + \"/\" + name) == True):\n",
    "                    y.append(makams.index(makam))\n",
    "                    break\n",
    "            \n",
    "            with open(os.path.join(root, name)) as f:\n",
    "                content = f.read()\n",
    "                all_qpitch.append(content)\n",
    "print(\"File number:\", len(y))\n",
    "print(\"Array length:\", len(all_qpitch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Pading input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "top_k = 636 #53*4*3\n",
    "tokenizer = Tokenizer(num_words=top_k, split='\\n')\n",
    "tokenizer.fit_on_texts(all_qpitch)\n",
    "seqs = tokenizer.texts_to_sequences(all_qpitch)\n",
    "print(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 22  8 ... 34  6  1]\n",
      " [ 1 60  9 ... 51  4  1]\n",
      " [ 1 28  3 ... 38  9  1]\n",
      " ...\n",
      " [ 2 12  8 ... 38  9  1]\n",
      " [ 1 20  5 ... 47  4  2]\n",
      " [ 1 47  4 ... 38  9  2]]\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Padding\n",
    "X = sequence.pad_sequences(seqs, maxlen = 10000, padding='post')\n",
    "print(X)\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.asarray(y), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 20)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word embedding\n",
    "embedding_vector_len = 8 #max pitch value length: 4, comma, significance value of length 1, newline \n",
    "\n",
    "#Network topology\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(top_k, embedding_vector_len, input_length=len(X[0])))\n",
    "model.add(Embedding(top_k, embedding_vector_len, input_length=10000)) #smaller input length for testing\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 10000, 8)          5088      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10000, 8)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 70)                22120     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "=================================================================\n",
      "Total params: 28,628\n",
      "Trainable params: 28,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "670/670 [==============================] - 127s 189ms/step - loss: 0.4521 - accuracy: 0.9001\n",
      "Epoch 2/5\n",
      "670/670 [==============================] - 128s 191ms/step - loss: 0.2239 - accuracy: 0.9499\n",
      "Epoch 3/5\n",
      "670/670 [==============================] - 124s 186ms/step - loss: 0.2102 - accuracy: 0.9500\n",
      "Epoch 4/5\n",
      "670/670 [==============================] - 124s 185ms/step - loss: 0.2067 - accuracy: 0.9500\n",
      "Epoch 5/5\n",
      "670/670 [==============================] - 123s 184ms/step - loss: 0.2049 - accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a639da9d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 9s 26ms/step\n",
      "[0.19945193502036007, 0.9499999284744263]\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
