{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Makam Recognition\n",
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from mutagen.mp3 import MP3\n",
    "import librosa\n",
    "from scipy.interpolate import interp2d \n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from math import floor\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.load_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading using provided folds and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------PARAMETERS--------#\n",
    "\n",
    "#Choose truncation option\n",
    "# 1 : 15 seconds starting from the start\n",
    "# 2 : 15 seconds around the middle\n",
    "# 3 : 15 seconds from the end\n",
    "trunc_option = 2\n",
    "\n",
    "#Choose bins and bins per octave\n",
    "n_bins = 371\n",
    "bins_per_octave = 53\n",
    "\n",
    "#--------------------------#\n",
    "\n",
    "#Ignore mp3 read warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "\n",
    "#Arrays containing all constant-Q transforms of the soundfiles per fold\n",
    "X_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Array containing all makam labels per fold\n",
    "y_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Import folds\n",
    "f = open(\"./dlfm_makam_recognition_data/folds_updated.json\")\n",
    "folds = json.load(f)\n",
    "\n",
    "file_names = []\n",
    "\n",
    "#Compute cqts and import labels\n",
    "for i in range(2): #in number of folds\n",
    "    \n",
    "    \n",
    "    #compute all training cqts and import train labels\n",
    "    for source in range(len(folds[i][1][\"training\"][\"sources\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"training\"][\"sources\"][source] + \".mp3\")\n",
    "    \n",
    "        if ((file_name in file_names) == False):\n",
    "            file_names.append(file_name)\n",
    "            \n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        audio = MP3(file_name)\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        X_train[i].append(cqt)\n",
    "        \n",
    "        #import makam training label\n",
    "        y_train[i].append(folds[i][1][\"training\"][\"modes\"][source])\n",
    "        \n",
    "        \n",
    "    #compute all testing cqts and import test labels\n",
    "    for ref in range(len(folds[i][1][\"testing\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"testing\"][ref][\"source\"] + \".mp3\")\n",
    "        \n",
    "        if ((file_name in file_names) == False):\n",
    "            file_names.append(file_name)\n",
    "            \n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        X_test[i].append(cqt)\n",
    "        \n",
    "        #import makam testing label\n",
    "        y_test[i].append(folds[i][1][\"testing\"][ref][\"mode\"])\n",
    "        \n",
    "    print(\"Fold\", i, \"loaded.\")\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(\"X_train shape:\", len(X_train), X_train[0].shape)\n",
    "print(\"X_test shape:\", len(X_test), X_test[0].shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"y_test shape:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encode target vector\n",
    "Y_train = to_categorical(np.asarray(y_train))\n",
    "Y_test = to_categorical(np.asarray(y_test))\n",
    "#channel dimension\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = (np.asarray(X_train[i])).reshape(len(X_train[i]), X_train[i][0].shape[0], X_train[i][0].shape[1], 1)\n",
    "    X_test[i] = (np.asarray(X_test[i])).reshape(len(X_test[i]), X_test[i][0].shape[0], X_test[i][0].shape[1], 1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"y_test shape:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(len(folds)):\n",
    "    #Network topology\n",
    "    model = Sequential()\n",
    "\n",
    "    #3 convolutional layers\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), activation='relu', input_shape=(X_train[i][0].shape[0], X_train[i][0].shape[1], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "    #Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "for i in range(len(folds)):\n",
    "    history = model[i].fit(X_train[i], Y_train[i], validation_split=0.25, epochs=10, batch_size=30)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "y_pred = []\n",
    "for i in range(len(folds)):\n",
    "    score = model[i].evaluate(X_test[i], Y_test[i], verbose=1)\n",
    "    scores.append(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
