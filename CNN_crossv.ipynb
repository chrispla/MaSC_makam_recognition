{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Neural Network for Makam Recognition\n",
    "10-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from mutagen.mp3 import MP3\n",
    "import librosa\n",
    "from scipy.interpolate import interp2d \n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "from math import floor\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('cnn10fold.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "dill.load_session('cnn1fold.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading using provided folds and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading fold 0.\n",
      "Loading training 900/900\n",
      "Loading testing 100/100\n",
      "Fold loading completed.\n",
      "X_train shape: 10 900 (371, 646)\n",
      "X_test shape: 10 100 (371, 646)\n",
      "y_train shape: 10\n",
      "y_test shape: 10\n"
     ]
    }
   ],
   "source": [
    "#--------PARAMETERS--------#\n",
    "\n",
    "#Choose truncation option\n",
    "# 1 : 15 seconds starting from the start\n",
    "# 2 : 15 seconds around the middle\n",
    "# 3 : 15 seconds from the end\n",
    "trunc_option = 2\n",
    "\n",
    "#Choose bins and bins per octave\n",
    "n_bins = 371\n",
    "bins_per_octave = 53\n",
    "\n",
    "#--------------------------#\n",
    "\n",
    "#Ignore mp3 read warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"PySoundFile failed. Trying audioread instead.\")\n",
    "\n",
    "makams = [\"Acemasiran\", \"Acemkurdi\", \"Bestenigar\", \"Beyati\", \"Hicaz\", \"Hicazkar\", \"Huseyni\", \"Huzzam\", \"Karcigar\", \"Kurdilihicazkar\", \"Mahur\", \"Muhayyer\", \"Neva\", \"Nihavent\", \"Rast\", \"Saba\", \"Segah\", \"Sultaniyegah\", \"Suzinak\", \"Ussak\"]\n",
    "\n",
    "#Arrays containing all constant-Q transforms of the soundfiles per fold\n",
    "X_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "X_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Array containing all makam labels per fold\n",
    "y_train = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_test = [[],[],[],[],[],[],[],[],[],[]]\n",
    "\n",
    "#Import folds\n",
    "f = open(\"./dlfm_makam_recognition_data/folds_updated.json\")\n",
    "folds = json.load(f)\n",
    "\n",
    "\n",
    "#Compute cqts and import labels\n",
    "for i in range(10): #in number of folds\n",
    "    \n",
    "    print(\"\\nLoading fold \" + str(i) + \".\")\n",
    "    \n",
    "    #compute all training cqts and import train labels\n",
    "    for source in range(len(folds[i][1][\"training\"][\"sources\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"training\"][\"sources\"][source] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        audio = MP3(file_name)\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        #Normalization\n",
    "        cqt = (cqt - np.mean(cqt)) / (np.std(cqt) + 1e-8)\n",
    "\n",
    "        X_train[i].append(cqt)\n",
    "        \n",
    "        #import makam training label\n",
    "        y_train[i].append(makams.index(folds[i][1][\"training\"][\"modes\"][source]))\n",
    "        \n",
    "        sys.stdout.write(\"\\rLoading training %i/900\" % (source+1))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    print()\n",
    "    \n",
    "    #compute all testing cqts and import test labels\n",
    "    for ref in range(len(folds[i][1][\"testing\"])):\n",
    "        \n",
    "        file_name = (\"./soundfiles/\" + folds[i][1][\"testing\"][ref][\"source\"] + \".mp3\")\n",
    "\n",
    "        #get file duration for loading\n",
    "        try:\n",
    "            audio = MP3(file_name)\n",
    "        except:\n",
    "            print(\"Problem with:\", file_name)\n",
    "            continue\n",
    "        duration = audio.info.length\n",
    "        \n",
    "        #load 15 seconds from the mp3 according to truncation option\n",
    "        if (trunc_option == 1): #15 seconds form the start\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 2): #15 seconds around the center\n",
    "            offset = (duration-15)/2\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "            \n",
    "        if (trunc_option == 3): #15 seconds from the end\n",
    "            offset = duration-15\n",
    "            #load soundfile\n",
    "            y, sr = librosa.core.load(file_name, offset=offset, duration=15)\n",
    "            #compute the constant-Q transform from audio signal\n",
    "            cqt = librosa.core.cqt(y, sr, n_bins=n_bins, bins_per_octave=bins_per_octave) #up to C7 in 53TET\n",
    "        \n",
    "        #Normalization\n",
    "        cqt = (cqt - np.mean(cqt)) / (np.std(cqt) + 1e-8)\n",
    "        \n",
    "        X_test[i].append(cqt)\n",
    "        \n",
    "        #import makam testing label\n",
    "        y_test[i].append(makams.index(folds[i][1][\"testing\"][ref][\"mode\"]))\n",
    "        \n",
    "        sys.stdout.write(\"\\rLoading testing %i/100\" % (ref+1))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "print(\"\\nFold loading completed.\")\n",
    "\n",
    "print(\"X_train shape:\", len(X_train), len(X_train[0]), X_train[0][0].shape)\n",
    "print(\"X_test shape:\", len(X_test), len(X_test[0]), X_test[0][0].shape)\n",
    "print(\"y_train shape:\", len(y_train))\n",
    "print(\"y_test shape:\", len(y_test))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (900, 371, 646, 1)\n",
      "X_test shape: (100, 371, 646, 1)\n",
      "Y_train shape: (1, 900, 20)\n",
      "Y_test shape: (1, 100, 20)\n"
     ]
    }
   ],
   "source": [
    "#one-hot encode target vector\n",
    "Y_train = []\n",
    "Y_test = []\n",
    "for i in range(10):\n",
    "    Y_train.append(to_categorical(np.asarray(y_train[i])))\n",
    "    Y_test.append(to_categorical(np.asarray(y_test[i])))\n",
    "Y_train = np.asarray(Y_train)\n",
    "Y_test = np.asarray(Y_test)\n",
    "#channel dimension\n",
    "for i in range(10):\n",
    "    X_train[i] = (np.asarray(X_train[i])).reshape(len(X_train[i]), X_train[i][0].shape[0], X_train[i][0].shape[1], 1)\n",
    "    X_test[i] = (np.asarray(X_test[i])).reshape(len(X_test[i]), X_test[i][0].shape[0], X_test[i][0].shape[1], 1)\n",
    "# X_train = np.asarray(X_train)\n",
    "# X_test = np.asarray(X_test)\n",
    "print(\"X_train shape:\", X_train[0].shape)\n",
    "print(\"X_test shape:\", X_test[0].shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 369, 644, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 184, 322, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 184, 322, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 182, 320, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 91, 160, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 91, 160, 64)       256       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 90, 159, 64)       16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 45, 79, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 45, 79, 64)        256       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 227520)            0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                14561344  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 20)                1300      \n",
      "=================================================================\n",
      "Total params: 14,617,428\n",
      "Trainable params: 14,617,044\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in range(10):\n",
    "    #Network topology\n",
    "    model = Sequential()\n",
    "\n",
    "    #3 convolutional layers\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[0].shape[1], X_train[0].shape[2], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(X_train[0].shape[1], X_train[0].shape[2], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(filters=64, kernel_size=(2,2), activation='relu', input_shape=(X_train[0].shape[1], X_train[0].shape[2], 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(20, activation='softmax'))\n",
    "    \n",
    "    #Optimizer\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    \n",
    "    #Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 675 samples, validate on 225 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py:96: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675/675 [==============================] - 222s 329ms/step - loss: 3.3396 - accuracy: 0.0800 - val_loss: 2.9984 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "675/675 [==============================] - 206s 305ms/step - loss: 2.7405 - accuracy: 0.1274 - val_loss: 3.0024 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "675/675 [==============================] - 211s 313ms/step - loss: 2.5463 - accuracy: 0.1793 - val_loss: 3.0206 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "675/675 [==============================] - 221s 328ms/step - loss: 2.3494 - accuracy: 0.2104 - val_loss: 3.0061 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "675/675 [==============================] - 223s 330ms/step - loss: 2.1857 - accuracy: 0.2504 - val_loss: 2.9952 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "histories = []\n",
    "for i in range(1):\n",
    "    history = models[i].fit(X_train[i], Y_train[i], validation_split=0.25, epochs=50, batch_size=32)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 8s 84ms/step\n",
      "100/100 [==============================] - 8s 77ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = [[],[],[],[],[],[],[],[],[],[]]\n",
    "y_pred = [[],[],[],[],[],[],[],[],[],[]]\n",
    "for i in range(1):\n",
    "    scores[i].append(models[i].evaluate(X_test[i], Y_test[i], verbose=1))\n",
    "    y_pred[i].append(np.argmax(models[i].predict(X_test[i], verbose=1)))\n",
    "scores = np.asarray(scores)\n",
    "y_pred = np.asarray(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1995]) list([]) list([]) list([]) list([]) list([]) list([])\n",
      " list([]) list([]) list([])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_test=np.asarray(y_test)\n",
    "cms = np.zeros((20,20))\n",
    "for i in range(10):\n",
    "    cms += confusion_matrix(y_test[i], y_pred[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(cms)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
