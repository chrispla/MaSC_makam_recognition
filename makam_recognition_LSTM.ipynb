{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makam pitch sequence classification with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pitch files\n",
    "\n",
    "Before proceeding, the pitch files on the CompMusic Dunya makam corpus need to be converted in the quantized pitch series encoding constructed as described in the pseudocode below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for (all lines):\n",
    "--->delete value if 0\n",
    "--->quantize value to scale (e.g. 53ET) // pad start of pitch value with zeros appropriately so that the length of the pitch value is 5 e.g. 130 -> 00130\n",
    "    \n",
    "for (all lines):\n",
    "--->merge all neighboring values to one, and keep track of the number of consecutive occurrences k e.g. 1300\\n 1200\\n 1200\\n 1200\\n 760\\n 760\\n will become 1300,1\\n 1200,3\\n 760,2\\n\n",
    "    \n",
    "find kmin and kmax\t\n",
    "\n",
    "for (all lines):\n",
    "--->if k < (kmin + 0.25*(kmax-kmin)): replace with 1\n",
    "--->if (kmin + 0.25*(kmax-kmin)) < k < (kmin + 0.75*(kmax-kmin)): replace with 2\n",
    "--->If k > (kmin + 0.75*(kmax-kmin)): replace with 3\n",
    "\n",
    "//We now have a quantized pitch series encoding with a line format of pitch,significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading, octave folded encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File number: 1000\n",
      "Array length: 1000\n"
     ]
    }
   ],
   "source": [
    "#quantized octave-folded pitch file directory\n",
    "ofq_read_dir = \"./qdata/\" \n",
    "\n",
    "#Makam list for more efficient file searching during label retrieval\n",
    "makams = [\"Acemasiran\", \"Acemkurdi\", \"Bestenigar\", \"Beyati\", \"Hicaz\", \"Hicazkar\", \"Huseyni\", \"Huzzam\", \"Karcigar\", \"Kurdilihicazkar\", \"Mahur\", \"Muhayyer\", \"Neva\", \"Nihavent\", \"Rast\", \"Saba\", \"Segah\", \"Sultaniyegah\", \"Suzinak\", \"Ussak\"]\n",
    "\n",
    "all_qpitch = [] #array holding all quantized pitch series as strings\n",
    "y = [] #holds makam labels\n",
    "max_length = 0\n",
    "for root, dirs, files in os.walk(ofq_read_dir):\n",
    "    for name in files:\n",
    "        if '.pitch' in name:\n",
    "            #retrieve label from parent of original path\n",
    "            for makam in makams:\n",
    "                if (os.path.isfile(\"./otmm_makam_recognition_dataset/data/\" + makam + \"/\" + name) == True):\n",
    "                    y.append(makams.index(makam))\n",
    "                    break\n",
    "            \n",
    "            with open(os.path.join(root, name)) as f:\n",
    "                content = f.read()\n",
    "                all_qpitch.append(content)\n",
    "print(\"File number:\", len(y))\n",
    "print(\"Array length:\", len(all_qpitch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Pading input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.1,2\n",
      "200.8,1\n",
      "198.1,1\n",
      "200.8,1\n",
      "203.4,1\n",
      "206.1,1\n",
      "208.8,1\n",
      "211.5,1\n",
      "208.8,1\n",
      "206.1,1\n",
      "203.4,1\n",
      "208.8,1\n",
      "206.\n",
      "[129, 23, 5, 23, 43, 48, 49, 42, 49, 48, 43, 49, 48, 43, 48, 43, 23, 5, 2, 5, 23, 5, 2, 129, 2, 5, 2, 129, 2, 129, 2, 5, 2, 129, 2, 5, 2, 5, 23, 5, 23, 5, 2, 5, 23, 28, 51, 170, 51, 28, 51, 54, 46, 33, 46, 54, 51, 28, 21, 28, 51, 54, 51, 28, 51, 28, 51, 28, 51, 28, 51, 170, 21, 28, 51, 62, 71, 64, 67, 70, 73, 72, 66, 59, 66, 72, 73, 70, 67, 70, 73, 72, 66, 72, 73, 72, 66, 59, 56, 53]\n"
     ]
    }
   ],
   "source": [
    "#Tokenization\n",
    "print(all_qpitch[0][0:100])\n",
    "top_k = 500\n",
    "tokenizer = Tokenizer(num_words=top_k, filters='', split='\\n')\n",
    "tokenizer.fit_on_texts(all_qpitch)\n",
    "seqs = tokenizer.texts_to_sequences(all_qpitch)\n",
    "print(seqs[0][0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34  44  41  44  34  44  34  44  10  17  41  44  34  44  17  41  45  38\n",
      "  45  38 198  38 198  38 198  29  33  46  54  51  28  21  37  47  19  14\n",
      "  24  61  76  80  82  84  78  55  50  68  89  94  89  68  50  84  82  24\n",
      "  19  21  12   2   5  23  43  48  49  42  26   8   1   3  18  31 150  34\n",
      "  44 160 150  34  44  34  44  41  17  10  11  16  13   6  13  16 154  16\n",
      "  13  16  11 157 135  16  13   6   9  22]\n"
     ]
    }
   ],
   "source": [
    "#Padding\n",
    "X = sequence.pad_sequences(np.asarray(seqs), maxlen = 10000, padding='post')\n",
    "#print(X)\n",
    "print(X[1][0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_c = to_categorical(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, np.asarray(y_c), test_size=0.33, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network topology\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Embedding(top_k, embedding_vector_len, input_length=len(X[0])))\n",
    "model.add(Embedding(500, 64, input_length=10000)) #smaller input length for testing\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 10000, 64)         32000     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 10000, 32)         6176      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 5000, 32)          0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 70)                28840     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                1420      \n",
      "=================================================================\n",
      "Total params: 68,436\n",
      "Trainable params: 68,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'], )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 448 samples, validate on 222 samples\n",
      "Epoch 1/10\n",
      "448/448 [==============================] - 34s 76ms/step - loss: 0.6836 - accuracy: 0.7235 - val_loss: 0.6666 - val_accuracy: 0.8809\n",
      "Epoch 2/10\n",
      "448/448 [==============================] - 35s 77ms/step - loss: 0.6267 - accuracy: 0.8603 - val_loss: 0.5194 - val_accuracy: 0.8590\n",
      "Epoch 3/10\n",
      "448/448 [==============================] - 44s 99ms/step - loss: 0.4218 - accuracy: 0.8987 - val_loss: 0.3088 - val_accuracy: 0.9500\n",
      "Epoch 4/10\n",
      "448/448 [==============================] - 41s 91ms/step - loss: 0.2821 - accuracy: 0.9448 - val_loss: 0.2325 - val_accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "448/448 [==============================] - 45s 101ms/step - loss: 0.2277 - accuracy: 0.9497 - val_loss: 0.2070 - val_accuracy: 0.9500\n",
      "Epoch 6/10\n",
      "448/448 [==============================] - 43s 96ms/step - loss: 0.2100 - accuracy: 0.9500 - val_loss: 0.2023 - val_accuracy: 0.9500\n",
      "Epoch 7/10\n",
      "448/448 [==============================] - 42s 94ms/step - loss: 0.2086 - accuracy: 0.9500 - val_loss: 0.2018 - val_accuracy: 0.9500\n",
      "Epoch 8/10\n",
      "448/448 [==============================] - 44s 99ms/step - loss: 0.2071 - accuracy: 0.9500 - val_loss: 0.2017 - val_accuracy: 0.9500\n",
      "Epoch 9/10\n",
      "448/448 [==============================] - 45s 99ms/step - loss: 0.2074 - accuracy: 0.9500 - val_loss: 0.2012 - val_accuracy: 0.9500\n",
      "Epoch 10/10\n",
      "448/448 [==============================] - 46s 102ms/step - loss: 0.2053 - accuracy: 0.9500 - val_loss: 0.2009 - val_accuracy: 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a3dc43910>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=1, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330/330 [==============================] - 1s 3ms/step\n",
      "[0.19809791626352252, 0.9499999284744263]\n"
     ]
    }
   ],
   "source": [
    "#Model evaluation\n",
    "scores = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
