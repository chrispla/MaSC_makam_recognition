{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Makam pitch sequence classification with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pitch files\n",
    "\n",
    "Before proceeding, the pitch files on the CompMusic Dunya makam corpus need to be converted in the quantized pitch series encoding constructed as described in the pseudocode below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for (all lines):\n",
    "--->delete value if 0\n",
    "--->quantize value to scale (e.g. 53ET) // pad start of pitch value with zeros appropriately so that the length of the pitch value is 5 e.g. 130 -> 00130\n",
    "    \n",
    "for (all lines):\n",
    "--->merge all neighboring values to one, and keep track of the number of consecutive occurrences k e.g. 1300\\n 1200\\n 1200\\n 1200\\n 760\\n 760\\n will become 1300,1\\n 1200,3\\n 760,2\\n\n",
    "    \n",
    "find kmin and kmax\t\n",
    "\n",
    "for (all lines):\n",
    "--->if k < (kmin + 0.25*(kmax-kmin)): replace with 1\n",
    "--->if (kmin + 0.25*(kmax-kmin)) < k < (kmin + 0.75*(kmax-kmin)): replace with 2\n",
    "--->If k > (kmin + 0.75*(kmax-kmin)): replace with 3\n",
    "\n",
    "//We now have a quantized pitch series encoding with a line format of pitch,significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for file reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quantized pitch file directory\n",
    "q_read_dir = \"./otmm_makam_recognition_dataset/qdata/\" \n",
    "octq_read_dir = \"./otmm_makam_recognition_dataset/octfold_qdata/\" \n",
    "\n",
    "#Makam list for more efficient file searching during label retrieval\n",
    "makams = [\"Acemasiran\", \"Acemkurdi\", \"Bestenigar\", \"Beyati\", \"Hicaz\", \"Hicazkar\", \"Huseyni\", \"Huzzam\", \"Karcigar\", \"Kurdilihicazkar\", \"Mahur\", \"Muhayyer\", \"Neva\", \"Nihavent\", \"Rast\", \"Saba\", \"Segah\", \"Sultaniyegah\", \"Suzinak\", \"Ussak\"]\n",
    "\n",
    "X = [] #array holding pitch series split per line\n",
    "y = [] #holds makam labels\n",
    "max_length = 0\n",
    "for root, dirs, files in os.walk(q_read_dir):\n",
    "    for name in files:\n",
    "        if '.pitch' in name:\n",
    "            #retrieve label from parent of original path\n",
    "            for makam in makams:\n",
    "                if (os.path.isfile(\"./otmm_makam_recognition_dataset/data/\" + makam + \"/\" + name[:-4] + \".pitch\") == True):\n",
    "                    Y.append(makam)\n",
    "                    break\n",
    "            with open(os.path.join(root, name)) as f:\n",
    "                content = f.readlines()\n",
    "                content_length = len(content)\n",
    "                if (content_length > max_length):\n",
    "                    max_length = content_length\n",
    "                X.append(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "Pading input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 10000\n",
    "\n",
    "#sequence padding\n",
    "X = sequence.pad_sequences(pitch_seqs, maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library importing for deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word embedding\n",
    "embedding_vector_len = 8 #pitch value of length 5, comma, significance value, newline character\n",
    "\n",
    "#Network topology\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary_size, embedding_vector_len, input_length=max_seq_length))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation='sigmoid'))\n",
    "\n",
    "#Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
